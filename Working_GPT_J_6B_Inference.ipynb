{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Working GPT-J-6B Inference.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8CMw_dSQKfhT",
        "aO1UXepF-0Uq"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/opencoca/Chat/blob/master/Working_GPT_J_6B_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHIJVqHsh4An"
      },
      "source": [
        "# GPT-J-6B Inference \n",
        "\n",
        "This notebook explores how to work with the [GPT-J-6B model](https://github.com/kingoflolz/mesh-transformer-jax/#GPT-J-6B). See the link for more details about the model, including evaluation metrics and credits.\n",
        "\n",
        "Please note it takes ~10 minutes for this notebook to fully spin up. Sometimes you will runout of ram when attempting to setup the model. If this happens factory restart the runtime and try again. If it contines to happen ...\n",
        "\n",
        "Start this notebok by clicking `Runtime > Run all` or clicking `⌘/Ctrl+F9`. Use `⌘` on Mac and `Ctrl` on Windows and Linux. \n",
        "\n",
        "Keep an eye on this as it spins up. Google likes to make sure you are not a bot and will stop things if you ignore the \"I'm not a robot\" popup."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CMw_dSQKfhT"
      },
      "source": [
        "## Prepare it to be used\n",
        "\n",
        "### Install Dependencies\n",
        "\n",
        "First we download the model and install some dependencies. This step takes at least 5 minutes (possibly longer depending on server load).\n",
        "\n",
        "!!! **Make sure you are using a TPU runtime!** !!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT1XmBc7BHwI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "750b28ea-001c-4cf6-c44d-de0aacfb99ba"
      },
      "source": [
        "#@title Install Tensorflow\n",
        "!pip install tensorflow==2.5.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.5.0\n",
            "  Downloading tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 454.3 MB 13 kB/s \n",
            "\u001b[?25hCollecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 71.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.37.1)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 85.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.3.0)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.17.3)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 93.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.2.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.1.0)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 79.7 MB/s \n",
            "\u001b[?25hCollecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.6.3)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (2.8.0)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 79.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.5.0) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.2.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68725 sha256=a332c2531aa12d5e9d74fd025a58bc2d22e61b8d9690de4d7b94b91d37ab414b\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, keras-nightly, gast, flatbuffers, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.47.0\n",
            "    Uninstalling grpcio-1.47.0:\n",
            "      Successfully uninstalled grpcio-1.47.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.2.0\n",
            "    Uninstalling absl-py-1.2.0:\n",
            "      Successfully uninstalled absl-py-1.2.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.4.0 grpcio-1.34.1 keras-nightly-2.5.0.dev2021032900 numpy-1.19.5 tensorflow-2.5.0 tensorflow-estimator-2.5.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7xAFw-LOYfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60769a48-878c-4b01-901c-302fef6c808f"
      },
      "source": [
        "#@title Install GPT-J-6B\n",
        "!apt install zstd\n",
        "\n",
        "# the \"slim\" version contain only bf16 weights and no optimizer parameters, which minimizes bandwidth and memory\n",
        "!time wget -c https://the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.zstd\n",
        "\n",
        "!time tar -I zstd -xf step_383500_slim.tar.zstd\n",
        "\n",
        "!git clone https://github.com/kingoflolz/mesh-transformer-jax.git\n",
        "!pip install -r mesh-transformer-jax/requirements.txt\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  zstd\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 278 kB of archives.\n",
            "After this operation, 1,141 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 zstd amd64 1.3.3+dfsg-2ubuntu1.2 [278 kB]\n",
            "Fetched 278 kB in 1s (331 kB/s)\n",
            "Selecting previously unselected package zstd.\n",
            "(Reading database ... 155653 files and directories currently installed.)\n",
            "Preparing to unpack .../zstd_1.3.3+dfsg-2ubuntu1.2_amd64.deb ...\n",
            "Unpacking zstd (1.3.3+dfsg-2ubuntu1.2) ...\n",
            "Setting up zstd (1.3.3+dfsg-2ubuntu1.2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "--2022-07-27 14:29:59--  https://the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.zstd\n",
            "Resolving the-eye.eu (the-eye.eu)... 162.213.130.6\n",
            "Connecting to the-eye.eu (the-eye.eu)|162.213.130.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9414712325 (8.8G) [application/octet-stream]\n",
            "Saving to: ‘step_383500_slim.tar.zstd’\n",
            "\n",
            "step_383500_slim.ta 100%[===================>]   8.77G  14.6MB/s    in 5m 52s  \n",
            "\n",
            "2022-07-27 14:35:52 (25.5 MB/s) - ‘step_383500_slim.tar.zstd’ saved [9414712325/9414712325]\n",
            "\n",
            "\n",
            "real\t5m52.790s\n",
            "user\t0m6.162s\n",
            "sys\t0m20.755s\n",
            "\n",
            "real\t0m47.510s\n",
            "user\t0m30.398s\n",
            "sys\t0m26.364s\n",
            "Cloning into 'mesh-transformer-jax'...\n",
            "remote: Enumerating objects: 791, done.\u001b[K\n",
            "remote: Total 791 (delta 0), reused 0 (delta 0), pack-reused 791\u001b[K\n",
            "Receiving objects: 100% (791/791), 320.06 KiB | 3.14 MiB/s, done.\n",
            "Resolving deltas: 100% (486/486), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/EleutherAI/lm-evaluation-harness/ (from -r mesh-transformer-jax/requirements.txt (line 9))\n",
            "  Cloning https://github.com/EleutherAI/lm-evaluation-harness/ to /tmp/pip-req-build-1k5prf5j\n",
            "  Running command git clone -q https://github.com/EleutherAI/lm-evaluation-harness/ /tmp/pip-req-build-1k5prf5j\n",
            "Requirement already satisfied: numpy~=1.19.5 in /usr/local/lib/python3.7/dist-packages (from -r mesh-transformer-jax/requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.45.0 in /usr/local/lib/python3.7/dist-packages (from -r mesh-transformer-jax/requirements.txt (line 2)) (4.64.0)\n",
            "Collecting wandb>=0.11.2\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.0 MB/s \n",
            "\u001b[?25hCollecting einops~=0.3.0\n",
            "  Downloading einops-0.3.2-py3-none-any.whl (25 kB)\n",
            "Collecting requests~=2.25.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 8.4 MB/s \n",
            "\u001b[?25hCollecting fabric~=2.6.0\n",
            "  Downloading fabric-2.6.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting optax==0.0.9\n",
            "  Downloading optax-0.0.9-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 96.1 MB/s \n",
            "\u001b[?25hCollecting dm-haiku==0.0.5\n",
            "  Downloading dm_haiku-0.0.5-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 77.9 MB/s \n",
            "\u001b[?25hCollecting ray[default]==1.4.1\n",
            "  Downloading ray-1.4.1-cp37-cp37m-manylinux2014_x86_64.whl (51.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 51.6 MB 255 kB/s \n",
            "\u001b[?25hCollecting jax~=0.2.12\n",
            "  Downloading jax-0.2.28.tar.gz (887 kB)\n",
            "\u001b[K     |████████████████████████████████| 887 kB 77.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r mesh-transformer-jax/requirements.txt (line 12)) (1.1.4)\n",
            "Requirement already satisfied: cloudpickle~=1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r mesh-transformer-jax/requirements.txt (line 13)) (1.3.0)\n",
            "Collecting tensorflow-cpu~=2.6.0\n",
            "  Downloading tensorflow_cpu-2.6.5-cp37-cp37m-manylinux2010_x86_64.whl (178.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 178.2 MB 51 kB/s \n",
            "\u001b[?25hCollecting google-cloud-storage~=1.36.2\n",
            "  Downloading google_cloud_storage-1.36.2-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 77.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart_open[gcs] in /usr/local/lib/python3.7/dist-packages (from -r mesh-transformer-jax/requirements.txt (line 17)) (5.2.1)\n",
            "Collecting func_timeout\n",
            "  Downloading func_timeout-4.3.5.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting fastapi\n",
            "  Downloading fastapi-0.79.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.18.2-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting lm_dataformat\n",
            "  Downloading lm_dataformat-0.0.20-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: pathy in /usr/local/lib/python3.7/dist-packages (from -r mesh-transformer-jax/requirements.txt (line 23)) (0.6.2)\n",
            "Collecting bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt\n",
            "  Downloading https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip\n",
            "\u001b[K     / 16.5 MB 41 kB/s\n",
            "\u001b[?25hCollecting datasets>=2.0.0\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "\u001b[K     |████████████████████████████████| 365 kB 81.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.1 in /usr/local/lib/python3.7/dist-packages (from lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (7.1.2)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.7/dist-packages (from lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (1.0.2)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (1.12.0+cu113)\n",
            "Collecting sqlitedict==1.6.0\n",
            "  Downloading sqlitedict-1.6.0.tar.gz (29 kB)\n",
            "Collecting pytablewriter==0.58.0\n",
            "  Downloading pytablewriter-0.58.0-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting sacrebleu==1.5.0\n",
            "  Downloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting rouge-score==0.0.4\n",
            "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Collecting pycountry==20.7.3\n",
            "  Downloading pycountry-20.7.3.tar.gz (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 83.4 MB/s \n",
            "\u001b[?25hCollecting numexpr==2.7.2\n",
            "  Downloading numexpr-2.7.2-cp37-cp37m-manylinux2010_x86_64.whl (471 kB)\n",
            "\u001b[K     |████████████████████████████████| 471 kB 73.4 MB/s \n",
            "\u001b[?25hCollecting pybind11==2.6.2\n",
            "  Downloading pybind11-2.6.2-py2.py3-none-any.whl (191 kB)\n",
            "\u001b[K     |████████████████████████████████| 191 kB 91.3 MB/s \n",
            "\u001b[?25hCollecting tqdm-multiprocess==0.0.11\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Collecting zstandard==0.15.2\n",
            "  Downloading zstandard-0.15.2-cp37-cp37m-manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 79.8 MB/s \n",
            "\u001b[?25hCollecting jsonlines==2.0.0\n",
            "  Downloading jsonlines-2.0.0-py3-none-any.whl (6.3 kB)\n",
            "Collecting mock==4.0.3\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Collecting openai==0.6.4\n",
            "  Downloading openai-0.6.4.tar.gz (159 kB)\n",
            "\u001b[K     |████████████████████████████████| 159 kB 94.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba==0.42.1 in /usr/local/lib/python3.7/dist-packages (from lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (0.42.1)\n",
            "Collecting nagisa==0.2.7\n",
            "  Downloading nagisa-0.2.7-cp37-cp37m-manylinux1_x86_64.whl (21.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.5 MB 692 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt->lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt->lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (1.7.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt->lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (2.5.0)\n",
            "Collecting tf-slim>=1.1\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 87.4 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 78.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from optax==0.0.9->-r mesh-transformer-jax/requirements.txt (line 7)) (0.15.0)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax==0.0.9->-r mesh-transformer-jax/requirements.txt (line 7)) (0.3.14+cuda11.cudnn805)\n",
            "Collecting chex>=0.0.4\n",
            "  Downloading chex-0.1.3-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 647 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5->-r mesh-transformer-jax/requirements.txt (line 8)) (3.7.4.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5->-r mesh-transformer-jax/requirements.txt (line 8)) (0.8.10)\n",
            "Collecting jmp>=0.0.2\n",
            "  Downloading jmp-0.0.2-py3-none-any.whl (16 kB)\n",
            "Collecting ujson\n",
            "  Downloading ujson-5.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nagisa==0.2.7->lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (1.15.0)\n",
            "Collecting DyNet\n",
            "  Downloading dyNET-2.1.2-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 77.6 MB/s \n",
            "\u001b[?25hCollecting msgfy<1,>=0.1.0\n",
            "  Downloading msgfy-0.2.0-py3-none-any.whl (4.3 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5\n",
            "  Downloading tcolorpy-0.1.2-py3-none-any.whl (7.9 kB)\n",
            "Collecting typepy[datetime]<2,>=1.1.1\n",
            "  Downloading typepy-1.3.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.7/dist-packages (from pytablewriter==0.58.0->lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (57.4.0)\n",
            "Collecting tabledata<2,>=1.1.3\n",
            "  Downloading tabledata-1.3.0-py3-none-any.whl (11 kB)\n",
            "Collecting pathvalidate<3,>=2.3.0\n",
            "  Downloading pathvalidate-2.5.0-py3-none-any.whl (19 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0\n",
            "  Downloading mbstrdecoder-1.1.0-py3-none-any.whl (7.8 kB)\n",
            "Collecting DataProperty<2,>=0.50.0\n",
            "  Downloading DataProperty-0.55.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.4.1->-r mesh-transformer-jax/requirements.txt (line 10)) (1.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.4.1->-r mesh-transformer-jax/requirements.txt (line 10)) (3.7.1)\n",
            "Collecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.3.12-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 80.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.4.1->-r mesh-transformer-jax/requirements.txt (line 10)) (1.34.1)\n",
            "Collecting gpustat\n",
            "  Downloading gpustat-0.6.0.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.4.1->-r mesh-transformer-jax/requirements.txt (line 10)) (0.14.1)\n",
            "Requirement already satisfied: pydantic>=1.8 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.4.1->-r mesh-transformer-jax/requirements.txt (line 10)) (1.9.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.4.1->-r mesh-transformer-jax/requirements.txt (line 10)) (4.3.3)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.4.1->-r mesh-transformer-jax/requirements.txt (line 10)) (3.13)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.3.4-py3-none-any.whl (246 kB)\n",
            "\u001b[K     |████████████████████████████████| 246 kB 81.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.4.1->-r mesh-transformer-jax/requirements.txt (line 10)) (3.17.3)\n",
            "Collecting aioredis\n",
            "  Downloading aioredis-2.0.1-py3-none-any.whl (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 9.7 MB/s \n",
            "\u001b[?25hCollecting opencensus\n",
            "  Downloading opencensus-0.10.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 72.7 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 72.4 MB/s \n",
            "\u001b[?25hCollecting colorful\n",
            "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[K     |████████████████████████████████| 201 kB 90.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score==0.0.4->lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (3.7)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.11.2->-r mesh-transformer-jax/requirements.txt (line 3)) (2.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.8.0-py2.py3-none-any.whl (153 kB)\n",
            "\u001b[K     |████████████████████████████████| 153 kB 86.7 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 88.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.11.2->-r mesh-transformer-jax/requirements.txt (line 3)) (5.4.8)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.25.1->-r mesh-transformer-jax/requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.25.1->-r mesh-transformer-jax/requirements.txt (line 5)) (2022.6.15)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.25.1->-r mesh-transformer-jax/requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.25.1->-r mesh-transformer-jax/requirements.txt (line 5)) (2.10)\n",
            "Collecting invoke<2.0,>=1.3\n",
            "  Downloading invoke-1.7.1-py3-none-any.whl (215 kB)\n",
            "\u001b[K     |████████████████████████████████| 215 kB 83.8 MB/s \n",
            "\u001b[?25hCollecting pathlib2\n",
            "  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting paramiko>=2.4\n",
            "  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 89.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt_einsum in /usr/local/lib/python3.7/dist-packages (from jax~=0.2.12->-r mesh-transformer-jax/requirements.txt (line 11)) (3.3.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.2->-r mesh-transformer-jax/requirements.txt (line 12)) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.2->-r mesh-transformer-jax/requirements.txt (line 12)) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.2->-r mesh-transformer-jax/requirements.txt (line 12)) (1.0.1)\n",
            "Collecting clang~=5.0\n",
            "  Downloading clang-5.0.tar.gz (30 kB)\n",
            "Collecting tensorboard<2.7,>=2.6.0\n",
            "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 70.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 14)) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 14)) (0.2.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 14)) (3.1.0)\n",
            "Collecting tensorflow-estimator<2.7,>=2.6.0\n",
            "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 79.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 14)) (0.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 14)) (1.6.3)\n",
            "Collecting grpcio>=1.28.1\n",
            "  Downloading grpcio-1.47.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 70.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 14)) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 14)) (1.1.2)\n",
            "Collecting keras<2.7,>=2.6.0\n",
            "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 80.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 14)) (1.12)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 14)) (0.37.1)\n",
            "Collecting google-resumable-media<2.0dev,>=1.2.0\n",
            "  Downloading google_resumable_media-1.3.3-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth<2.0dev,>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 15)) (1.35.0)\n",
            "Collecting google-cloud-core<2.0dev,>=1.4.1\n",
            "  Downloading google_cloud_core-1.7.3-py2.py3-none-any.whl (28 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->-r mesh-transformer-jax/requirements.txt (line 16)) (21.3)\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 89.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r mesh-transformer-jax/requirements.txt (line 16)) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 40.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->-r mesh-transformer-jax/requirements.txt (line 16)) (4.12.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax==0.0.9->-r mesh-transformer-jax/requirements.txt (line 7)) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax==0.0.9->-r mesh-transformer-jax/requirements.txt (line 7)) (0.1.7)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (6.0.1)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (0.3.5.1)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (0.70.13)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 98.4 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.11.1\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 93.3 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 15)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 15)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 15)) (4.9)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 15)) (1.31.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 15)) (1.56.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 15)) (2022.1)\n",
            "Collecting google-crc32c<2.0dev,>=1.0\n",
            "  Downloading google_crc32c-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow-cpu~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 14)) (1.5.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask~=1.1.2->-r mesh-transformer-jax/requirements.txt (line 12)) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->-r mesh-transformer-jax/requirements.txt (line 16)) (3.0.9)\n",
            "Collecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[K     |████████████████████████████████| 856 kB 87.3 MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.2-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.0 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 76.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4->fabric~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 6)) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->fabric~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 6)) (2.21)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.11.0->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 15)) (0.4.8)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting async-timeout>=4.0.2\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->-r mesh-transformer-jax/requirements.txt (line 16)) (3.8.1)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 91.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow-cpu~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 14)) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow-cpu~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 14)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow-cpu~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 14)) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow-cpu~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 14)) (1.8.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow-cpu~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 14)) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow-cpu~=2.6.0->-r mesh-transformer-jax/requirements.txt (line 14)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from typepy[datetime]<2,>=1.1.1->pytablewriter==0.58.0->lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->-r mesh-transformer-jax/requirements.txt (line 19)) (0.2.5)\n",
            "Collecting starlette==0.19.1\n",
            "  Downloading starlette-0.19.1-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.6 MB/s \n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from pathy->-r mesh-transformer-jax/requirements.txt (line 23)) (0.4.2)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[default]==1.4.1->-r mesh-transformer-jax/requirements.txt (line 10)) (21.4.0)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 83.1 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 71.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[default]==1.4.1->-r mesh-transformer-jax/requirements.txt (line 10)) (2.1.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from DyNet->nagisa==0.2.7->lm-eval==0.2.0->-r mesh-transformer-jax/requirements.txt (line 9)) (0.29.30)\n",
            "Collecting nvidia-ml-py3>=7.352.0\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "Collecting blessings>=1.6\n",
            "  Downloading blessings-1.7-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]==1.4.1->-r mesh-transformer-jax/requirements.txt (line 10)) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]==1.4.1->-r mesh-transformer-jax/requirements.txt (line 10)) (5.8.0)\n",
            "Collecting opencensus-context>=0.1.2\n",
            "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████▊   | 459.6 MB 1.1 MB/s eta 0:00:46"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# jax 0.2.12 is required due to a regression with xmap in 0.2.13\n",
        "!pip install mesh-transformer-jax/ jax==0.2.12"
      ],
      "metadata": {
        "id": "VcLHEUQPDlsy",
        "outputId": "20668b56-8c20-4a00-f19e-8ec3d2ef8cae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Invalid requirement: 'mesh-transformer-jax/'\n",
            "Hint: It looks like a path. File 'mesh-transformer-jax/' does not exist.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO1UXepF-0Uq"
      },
      "source": [
        "## Setup Model\n",
        "\n",
        "You may have to restart your runtime before this will work. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex0qJgaueZtJ"
      },
      "source": [
        "#@title Setup JAX for TPU use\n",
        "import os\n",
        "import requests \n",
        "from jax.config import config\n",
        "\n",
        "colab_tpu_addr = os.environ['COLAB_TPU_ADDR'].split(':')[0]\n",
        "url = f'http://{colab_tpu_addr}:8475/requestversion/tpu_driver0.1_dev20210607'\n",
        "requests.post(url)\n",
        "\n",
        "# The following is required to use TPU Driver as JAX's backend.\n",
        "config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIgUVdFLe4A8"
      },
      "source": [
        "Sometimes the next step errors for some reason, just run it again ¯\\\\\\_(ツ)\\_/¯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A5IGYSaeze3"
      },
      "source": [
        "#@title Import libraries\n",
        "import time\n",
        "\n",
        "import jax\n",
        "from jax.experimental import maps\n",
        "import numpy as np\n",
        "import optax\n",
        "import transformers\n",
        "\n",
        "from mesh_transformer.checkpoint import read_ckpt\n",
        "from mesh_transformer.sampling import nucleaus_sample\n",
        "from mesh_transformer.transformer_shard import CausalTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "QAgKq-X2kmba"
      },
      "source": [
        "#@title Set Network Parameters \n",
        "params = {\n",
        "  \"layers\": 28,\n",
        "  \"d_model\": 4096,\n",
        "  \"n_heads\": 16,\n",
        "  \"n_vocab\": 50400,\n",
        "  \"norm\": \"layernorm\",\n",
        "  \"pe\": \"rotary\",\n",
        "  \"pe_rotary_dims\": 64,\n",
        "\n",
        "  \"seq\": 2048,\n",
        "  \"cores_per_replica\": 8,\n",
        "  \"per_replica_batch\": 1,\n",
        "}\n",
        "\n",
        "per_replica_batch = params[\"per_replica_batch\"]\n",
        "cores_per_replica = params[\"cores_per_replica\"]\n",
        "seq = params[\"seq\"]\n",
        "\n",
        "\n",
        "params[\"sampler\"] = nucleaus_sample\n",
        "\n",
        "# here we \"remove\" the optimizer parameters from the model (as we don't need them for inference)\n",
        "params[\"optimizer\"] = optax.scale(0)\n",
        "\n",
        "mesh_shape = (jax.device_count() // cores_per_replica, cores_per_replica)\n",
        "devices = np.array(jax.devices()).reshape(mesh_shape)\n",
        "\n",
        "maps.thread_resources.env = maps.ResourceEnv(maps.Mesh(devices, ('dp', 'mp')))\n",
        "\n",
        "tokenizer = transformers.GPT2TokenizerFast.from_pretrained('gpt2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7kJZTkVQ2CZ",
        "cellView": "form"
      },
      "source": [
        "#@title Install Tracery \n",
        "#@markdown Tracery is a gramar for spining articles, stories, and text in general. https://github.com/aparrish/pytracery\n",
        "!pip install tracery"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwNETD2Uk8nu"
      },
      "source": [
        "#@title Create the network\n",
        "#@markdown ...loading neural weights from the downloaded files. \n",
        "#@markdown\n",
        "#@markdown  > *This can take around 5 minutes.*\n",
        "total_batch = per_replica_batch * jax.device_count() // cores_per_replica\n",
        "\n",
        "network = CausalTransformer(params)\n",
        "\n",
        "network.state = read_ckpt(network.state, \"step_383500/\", devices.shape[1])\n",
        "\n",
        "network.state = network.move_xmap(network.state, np.zeros(cores_per_replica))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-eT7Sw6if4J"
      },
      "source": [
        "# Run Model\n",
        "\n",
        "Finally, we are ready to infer with the model! The first sample takes around a minute due to compilation, but after that it should only take about 10 seconds per sample.\n",
        "\n",
        "Feel free to mess with the different sampling parameters (top_p and temp), as well as the length of the generations (gen_len, causes a recompile when initially changed - recompiles will be cached).\n",
        "\n",
        "You can also change other things like per_replica_batch in the previous cells to change how many generations are done in parallel. A larger batch has higher latency but higher throughput when measured in tokens generated/s. This is useful for doing things like best-of-n cherry picking.\n",
        "\n",
        "*Tip for best results: Make sure your prompt does not have any trailing spaces, which tend to confuse the model due to the BPE tokenization used during training.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuZq54dh8opl"
      },
      "source": [
        "# allow text wrapping in generated output: https://stackoverflow.com/a/61401455\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVzs2TYlvYeX"
      },
      "source": [
        "def infer(context, top_p=0.9, temp=1.0, gen_len=256):\n",
        "    tokens = tokenizer.encode(context)\n",
        "\n",
        "    provided_ctx = len(tokens)\n",
        "    pad_amount = seq - provided_ctx\n",
        "\n",
        "    padded_tokens = np.pad(tokens, ((pad_amount, 0),)).astype(np.uint32)\n",
        "    batched_tokens = np.array([padded_tokens] * total_batch)\n",
        "    length = np.ones(total_batch, dtype=np.uint32) * len(tokens)\n",
        "\n",
        "    start = time.time()\n",
        "    output = network.generate(batched_tokens, length, gen_len, {\"top_p\": np.ones(total_batch) * top_p, \"temp\": np.ones(total_batch) * temp})\n",
        "\n",
        "    samples = []\n",
        "    decoded_tokens = output[1][0]\n",
        "\n",
        "    for o in decoded_tokens[:, :, 0]:\n",
        "      samples.append(f\"\\033[1m{context}\\033[0m{tokenizer.decode(o)}\")\n",
        "\n",
        "    #print(f\"completion done in {time.time() - start:06}s\")\n",
        "    #this should instead be added to the object returned infered.samples and infered.completion_time\n",
        "    return samples\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjWw1zkEOP8z"
      },
      "source": [
        "#@markdown The first time that infrences are run for a given length takes imensly longer than on repeated runs. For this reason we spin up the inference engine with a few sample runs. With this out of the way we can quickly experiment with our infrence engine. \n",
        "\n",
        "context = \"\"\"# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL AT SPACES CITÉ MULTIMÉDIA\n",
        "\n",
        "## The Old Port of Montreal is a\"\"\"\n",
        "\n",
        "for i in [32,64,128,256,512,1024]:\n",
        "  print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
        "  print(f\" ## Infering context with a gen_len of {i} this should take ~ {i/16} sec. when run again ##\")\n",
        "  print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
        "  print(infer(context, gen_len=i)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO89-sKMrucR"
      },
      "source": [
        "# Example prompts\n",
        "\n",
        "We've compiled the model. At this point it should only take about 15 seconds per sample. The first time you run inference on a new dataset takes longer than usual because of compilation to build the graph and write data into disk buffers for fast access by CPUs/GPUs.\n",
        "\n",
        "The following parameters can be adjusted: top_p, temp, gen_len. When changing the length of generations (gen_len), recompilation is required to maintain accuracy and consistency in results.\n",
        "\n",
        "You can also change other things like the number of generations done in parallel and how many samples are generated. In addition, you can increase or decrease the batch size for latency/throughput tradeoffs as well. This is useful when performing best-of-n cherry picking tasks where throughput needs to be maximized with minimum batch time delay on each sample generation process.\n",
        "\n",
        "To get the best results, make sure your prompt does not have any trailing spaces. This is because BPE tokenization can be confused by them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ViSfFkOUbS"
      },
      "source": [
        "## Simple Inference "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EStwU8WqXnBD"
      },
      "source": [
        "### Set Sampling Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akM-tZFTXnBE"
      },
      "source": [
        "#@markdown ### Leave this alone unless you know what you are doing ... or are just having fun experimenting.\n",
        "#@markdown \n",
        "#@markdown - - - \n",
        "#@markdown Top_p controls diversity/quality. The higher our top_p the more rich and nuanced oir inferences can be.\n",
        "top_p = 0 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "#@markdown - - - \n",
        "#@markdown Temp controls randomnes. Low temps make for mechanical inferences.\n",
        "temp = 0.6 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "#@markdown - - - \n",
        "#@markdown Gen_len adjects the length of text infered.\n",
        "#@markdown Specifcily it adustes the nember of tokens (~4 per engish word).\n",
        "#@markdown\n",
        "#@markdown *Note: Changing gen_len will cause long wait times when first setting lengs that have not been set before.*\n",
        "#@markdown  \n",
        "gen_len = 512 #@param {type: \"slider\", min:64, max: 1024, step: 64}\n",
        "#@markdown - - - \n",
        "#@markdown Generate controls the number of inferences that will be generated.\n",
        "generate = 1 #@param {type: \"slider\", min:1, max: 12, step: 1}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wUL-ryfYueS"
      },
      "source": [
        "### Text examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvlAK6RbCJYg"
      },
      "source": [
        "#@title Raw Context \n",
        "top_p = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "temp = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "gen_len = 256 #@param {type: \"slider\", min:64, max: 512, step: 64}\n",
        "\n",
        "\n",
        "#print(\"Enter/Paste your content. Ctrl-D or Ctrl-Z ( windows ) to save it.\")\n",
        "#context = []\n",
        "#while True:\n",
        "#    try:\n",
        "#        line = input()\n",
        "#    except EOFError:\n",
        "#        break\n",
        "#    context.append(line)\n",
        "\n",
        "context = \"\"\"\"\n",
        "\n",
        "Title: Bitcoin back above $50,000 as recovery continues\n",
        "Date: 23 August\n",
        "Article:\n",
        "\n",
        "The price of Bitcoin has risen above $50,000 \n",
        "(£36,480) for the first time in three months\n",
        "as the cryptocurrency continues to recover \n",
        "from a deep slump.\n",
        "\n",
        "The coin fell sharply in May after a crackdown\n",
        "in China and a decision by Elon Musk's Tesla \n",
        "not to accept it as payment any more.\n",
        "\n",
        "But investor sentiment is improving as more \n",
        "mainstream financial companies begin using\n",
        "the digital currency.\n",
        "\n",
        "Summerized:\"\"\"\n",
        "\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=gen_len, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2omRWxDivro",
        "cellView": "form"
      },
      "source": [
        "#@title Expand into a script \n",
        "#@markdown The will expand a lead into a script bassed on the opening of pulp fiction.\n",
        "expand_this = \"Feline biology is amazing\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - - - - - - - - - - - - - - - - - - - - - - - - -\n",
        "#@markdown These options don't need to be adjusted.\n",
        "top_p = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "temp = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "gen_len = 512 #@param {type: \"slider\", min:64, max: 2048, step: 64}\n",
        "generate = 1 #@param {type: \"slider\", min:1, max: 12, step: 1}\n",
        "#@markdown - - - - - - - - - - - - - - - - - - - - - - - - -\n",
        "\n",
        "\n",
        "context = \"\"\"\n",
        "\n",
        "INT. COMPUTER LAB – MORNING\n",
        "\n",
        "A normal computer lab, an office or university, Toronto Canada.\n",
        "It's about 9:00 in the morning. While the place isn't jammed,\n",
        "there's a healthy number of people working, drinking coffee, \n",
        "reading at their computers.\n",
        "\n",
        "Two of these people are a YOUNG MAN and a YOUNG WOMAN. The\n",
        "Young Man has a slight working-class English accent.\n",
        "\n",
        "             YOUNG MAN\n",
        "  I want to tell you about what we've been studying.\n",
        "\n",
        "             YOUNG WOMAN\n",
        "  Oh? What have you been focusing on? \n",
        "\n",
        "             YOUNG MAN\n",
        "  {expand_this}. For example\"\"\"\n",
        "\n",
        "\n",
        "for x in range(generate):\n",
        "  try:\n",
        "    print(infer(top_p=top_p, \n",
        "                temp=temp, \n",
        "                gen_len=gen_len, \n",
        "                context=context.format(expand_this = expand_this))[0])\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN8f4mvA97nG"
      },
      "source": [
        "#@title Make a title sound more academic \n",
        "#@markdown  \n",
        "improve_this = \"we're going ti make an instrument using the potentiometer \" #@param {type:\"string\"}\n",
        "#@markdown - - -\n",
        "top_p = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "temp = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "gen_len = 64 #@param {type: \"slider\", min:64, max: 2048, step: 64}\n",
        "generate = 12 #@param {type: \"slider\", min:1, max: 12, step: 1}\n",
        "\n",
        "context = \"\"\"\n",
        "Instead of saying, \"{improve_this}\" a better shibboleth would be, \\\"\"\"\"\n",
        "\n",
        "#Indie Hackers want to click on titles such as \n",
        "#use something with more punch\n",
        "\n",
        "for x in range(generate):\n",
        "  try:\n",
        "    print(infer(top_p=top_p, \n",
        "                temp=temp, \n",
        "                gen_len=gen_len, \n",
        "                context=context.format(improve_this = improve_this))[0].split('\"')[3])\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf63EvRmipH2"
      },
      "source": [
        "#@title Give headlines some more Clickbait \n",
        "improve_this = \"Make an instrument using the a light sensor \" #@param {type:\"string\"}\n",
        "#@markdown - - - - - - - - - - - - - - - - - - - - - - - - \n",
        "top_p = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "temp = 1 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "gen_len = 64 #@param {type: \"slider\", min:64, max: 2048, step: 64}\n",
        "generate = 12 #@param {type: \"slider\", min:1, max: 12, step: 1}\n",
        "\n",
        "context = \"\"\"\n",
        "You need to make your title more clickbate. So instead of,\n",
        "\"{improve_this}\" use something with more punch such as,\\\"\"\"\"\n",
        "\n",
        "\n",
        "for x in range(generate):\n",
        "  try:\n",
        "    print(infer(top_p=top_p, \n",
        "                temp=temp, \n",
        "                gen_len=gen_len, \n",
        "                context=context.format(improve_this = improve_this))[0].split('\"')[3])\n",
        "                #context=context.format(improve_this = improve_this))[0])\n",
        "\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvek96CyOnOh"
      },
      "source": [
        "#@title Generating inference prompts using tracery\n",
        "import tracery\n",
        "from tracery.modifiers import base_english\n",
        "\n",
        "rules = {\n",
        "    \n",
        "    'origin': 'Our team builds #imagine# new online #location# beyond',\n",
        "    'imagine': ['amazing', 'spectaculare' , 'bold', ],\n",
        "    'location': ['worlds', 'spaces', 'colabortion']\n",
        "}\n",
        "\n",
        "grammar = tracery.Grammar(rules)\n",
        "grammar.add_modifiers(base_english)\n",
        "\n",
        "for x in range(generate):\n",
        "  try:\n",
        "    print(infer(top_p=top_p, \n",
        "                temp=temp, \n",
        "                gen_len=gen_len, \n",
        "                context=grammar.flatten(\"#origin#\"))[0] + \"\\n\")\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5cJmv5ALxaM"
      },
      "source": [
        "#@title Generating inference prompts using tracery\n",
        "import tracery\n",
        "from tracery.modifiers import base_english\n",
        "\n",
        "rules = {\n",
        "    \n",
        "    'origin': '#this_semester# Jane #does# #good_bad# in class. We hope that she',\n",
        "    'this_semester': ['Our focus this semester was learning to program microcomputers, using sensors, and building electronic circuits.','This semester we focused on learning to build electric circuits, reading information from sensors, and programming microcontrollers.'],\n",
        "    'does': ['works', 'does' , 'particpates', 'performs' ],\n",
        "    'good_bad': ['well', 'competently', 'baddly']\n",
        "}\n",
        "\n",
        "grammar = tracery.Grammar(rules)\n",
        "grammar.add_modifiers(base_english)\n",
        "\n",
        "for x in range(generate):\n",
        "  try:\n",
        "    print(infer(top_p=top_p, \n",
        "                temp=temp, \n",
        "                gen_len=gen_len, \n",
        "                context=grammar.flatten(\"#origin#\"))[0] + \"\\n\")\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c9FzqkVcZyZ",
        "cellView": "form"
      },
      "source": [
        "#@title Article Generator \n",
        "title = \"Being your own Boss\" #@param {type:\"string\"}\n",
        "site = \"\" #@param {type:\"string\"}\n",
        "date = \"\" #@param {type:\"string\"}\n",
        "author = \"Jim Rohn\" #@param {type:\"string\"}\n",
        "tags = \"goals, drive, gtd\" #@param {type:\"string\"}\n",
        "lead = \"## Table of Content\" #@param {type:\"string\"}\n",
        "#@markdown - - -\n",
        "\n",
        "context = \"\"\"\n",
        "# {title}\n",
        "### Published:{date}\n",
        "### By:{author}\n",
        "##### Tags: {tags}\n",
        "### Site: {site}\n",
        "\n",
        "{lead}\n",
        "\"\"\"\n",
        "\n",
        "for x in range(generate):\n",
        "  print(infer(top_p=top_p, \n",
        "              temp=temp, \n",
        "              gen_len=gen_len, \n",
        "              context=context.format(title =title, \n",
        "                                     site = site, \n",
        "                                     date = date, \n",
        "                                     author = author, \n",
        "                                     tags = tags, \n",
        "                                     lead = lead))[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKpUf-M554f9",
        "cellView": "form"
      },
      "source": [
        "#@title Article generation { form-width: \"300px\" }\n",
        "title = \"COVID-19: What do vaccine passports in Quebec & Ontario mean for Canada's largest provinces? \" #@param {type:\"string\"}\n",
        "site = \"https://www.canada.ca/en/public-health/services/diseases/\" #@param {type:\"string\"}\n",
        "date = \"Sep 7, 2021\" #@param {type:\"string\"}\n",
        "author = \"\" #@param {type:\"string\"}\n",
        "tags = \"COVID-19, Quebec, Ontario, Canada\" #@param {type:\"string\"}\n",
        "lead = \"The passports are certificates that confirm vaccinations and allow people to enjoy eating\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#print(\"Enter/Paste your content. Ctrl-D or Ctrl-Z ( windows ) to save it.\")\n",
        "#context = []\n",
        "#while True:\n",
        "#    try:\n",
        "#        line = input()\n",
        "#    except EOFError:\n",
        "#        break\n",
        "#    context.append(line)\n",
        "\n",
        "context = \"\"\"\n",
        "# {title}\n",
        "### Published:{date}\n",
        "### By:{author}\n",
        "##### Tags: {tags}\n",
        "### Site: {site}\n",
        "\n",
        "{lead}\"\"\"\n",
        "\n",
        "for x in range(generate):\n",
        "  print(infer(top_p=top_p, \n",
        "              temp=temp, \n",
        "              gen_len=gen_len, \n",
        "              context=context.format(title =title, \n",
        "                                     site = site, \n",
        "                                     date = date, \n",
        "                                     author = author, \n",
        "                                     tags = tags, \n",
        "                                     lead = lead))[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka8vrZ-kN1Qi"
      },
      "source": [
        "## Code Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiXYadumWbT9"
      },
      "source": [
        "### Set Sampling Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSKHAVCYPt2W"
      },
      "source": [
        "#@markdown ### Leave this alone unless you know what you are doing ... or are just having fun experimenting.\n",
        "#@markdown \n",
        "#@markdown - - - \n",
        "#@markdown Top_p controls diversity/quality. The higher our top_p the more rich and nuanced oir inferences can be.\n",
        "top_p = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "#@markdown - - - \n",
        "#@markdown Temp controls randomnes. Low temps make for mechanical inferences.\n",
        "temp = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "#@markdown - - - \n",
        "#@markdown Gen_len adjects the length of text infered.\n",
        "#@markdown Specifcily it adustes the nember of tokens (~4 per engish word).\n",
        "#@markdown\n",
        "#@markdown *Note: Changing gen_len will cause long wait times when first setting lengs that have not been set before.*\n",
        "#@markdown  \n",
        "gen_len = 512 #@param {type: \"slider\", min:64, max: 1024, step: 64}\n",
        "#@markdown - - - \n",
        "#@markdown Generate controls the number of inferences that will be generated.\n",
        "generate = 1 #@param {type: \"slider\", min:1, max: 12, step: 1}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIGNc1D7XBQ-"
      },
      "source": [
        "### Python Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "phNf7ZPj3I8U"
      },
      "source": [
        "#@title Python Code - Simple \n",
        "#@markdown Generate code by just writng a comment and a name for a fuction \n",
        "python_comment = \"check if a number is prime or not\" #@param {type:\"string\"}\n",
        "#variable_n_val = \"youtube_video_url\" #@param {type:\"string\"}\n",
        "function_name = \"p\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "context = \"\"\"# {python_comment}\n",
        "\n",
        "def is_\"\"\".format(python_comment = python_comment, \n",
        "           function_name = function_name)\n",
        "\n",
        "for x in range(generate):\n",
        "  print(infer(top_p=top_p, temp=temp, gen_len=gen_len, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Gs97bc_DCNIY"
      },
      "source": [
        "#@title Python Code - Complex\n",
        "python_comment = \"detect security flaws \" #@param {type:\"string\"}\n",
        "variable_name =\"person_real_name\" #@param {type:\"string\"}\n",
        "variable_val = \"Isabelle Plante\" #@param {type:\"string\"}\n",
        "function_name = \"online_account_scan\" #@param {type:\"string\"}\n",
        "#@markdown - - -\n",
        "\n",
        "\n",
        "context = '''#!/usr/bin/env python3\n",
        "\n",
        "# {python_comment}\n",
        "\n",
        "{variable_name} = \"{variable_val}\"\n",
        "\n",
        "def {function_name}(n):\n",
        "  \"\"\"This'''.format(python_comment = python_comment,\n",
        "           variable_name = variable_name,\n",
        "           variable_val = variable_val,\n",
        "           function_name = function_name)\n",
        "\n",
        "for x in range(generate):\n",
        "  print(infer(top_p=top_p, temp=temp, gen_len=gen_len, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2u9WMX9Q-lG"
      },
      "source": [
        "#@title Vue Code - Simple { form-width: \"500px\" }\n",
        "comment = \"guest speakers\" #@param {type:\"string\"}\n",
        "#variable_n_val = \"youtube_video_url\" #@param {type:\"string\"}\n",
        "name = \"tab_1\" #@param {type:\"string\"}\n",
        "#@markdown - - - \n",
        "#@markdown Leave this alone unless you know ...\n",
        "top_p = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "temp = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "gen_len = 512 #@param {type:\"slider\", min:64, max:1024, step:64}\n",
        "generate = 1 #@param {type: \"slider\", min:1, max: 12, step: 1}\n",
        "\n",
        "context = \"\"\"\n",
        "<!-- Vue template for {comment} page -->\n",
        "<section>\n",
        "  <div id=\"app\" class=\"container\">\n",
        "    <div class=\"content\">\n",
        "      <div id=\"{name} \" class=\"\"\".format(comment = comment, \n",
        "           name = name)\n",
        "      \n",
        "print(infer(top_p=top_p, temp=temp, gen_len=gen_len, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xiwQxqCNdz9"
      },
      "source": [
        "# Examples of GPT genereated code.\n",
        "\n",
        "The following are examples of code generated in prior runs.\n",
        "\n",
        "Please paste interesting examples below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgb9xlP394_5"
      },
      "source": [
        "# check if a number is prime or not\n",
        "\n",
        "def is_prime(n):\n",
        "  \"\"\" \n",
        "  > returns true if n is a prime,\n",
        "  > false otherwise.\n",
        "  \"\"\"\n",
        "  for i in range(2, n):\n",
        "    if n % i == 0:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "print(is_prime(7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKo_2bvagu2K"
      },
      "source": [
        "# Program to check if a number is prime or not\n",
        "\n",
        "num = 9\n",
        "\n",
        "# Program to check if a number is prime or not\n",
        "\n",
        "def is_prime(n):\n",
        "    while n > 1:\n",
        "        while n % 2 == 0:\n",
        "            return False\n",
        "        n = n / 2\n",
        "    return True\n",
        "\n",
        "print(\"This is an example of a function that works but is quite wrong!\")\n",
        "\n",
        "for i in range(2, 20):\n",
        "  print(f\"Is {i} prime? {is_prime(i)}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOwWzOgflhW0"
      },
      "source": [
        "# check if a number is prime or not\n",
        "def is_prime(n):\n",
        "    for i in range(2, n):\n",
        "        if n % i == 0:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "is_prime(9)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}